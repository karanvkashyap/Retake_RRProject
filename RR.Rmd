---
title: "Alcohol Consumption and Average Grades"
author: "Karan Vijay Kashyap, Sandile Nhlalo-Sibanda"
date: "August, 2022"
output:
  html_document:
      theme: darkly
      highlight: tango
      toc: true
      toc_float: true
  
---

# Introduction
This project seeks to reproduce the research previously done on the determination of whether alcohol consumption has any prognostic significance over average student grades.
We're also interested in duplicating the original study to verify the correctness and if additional characteristics are significant predictors of student grades. Like the original author, we will not attempt to estimate student grade progression over marking periods because all of the dataset's attributes (except grades) stay consistent between marking periods and are fundamental descriptors of student backgrounds.

The project is organization of the project will follow the outline that resembles that of the original research's author (though will have some additions and some subtractions). The general structure will be as follows:

In the beginning, we will start with exploratory data analysis to see if the two tables (with math and Portuguese grades from original dataset) and (with math and english grades from survey dataset) may be combined.

We will then derive student average grades throughout grading periods by integrating the two tables and estimate three models: Linear Model, Regression Tree Model, and Random Forest Model.

Later, we acquired data from a survey for English and Math grades, and we will replicate the research on a fresh data set, estimating three models: Linear Model, Regression Tree Model, and Random Forest Model.

The goal of this study is to determine the effect of alcohol use on students' average grades.


# About Data
Original Dataset:
We have two csv file one for math grade and other for Portuguese grade which collected from two school and merged in one csv file based on subject. 
Number of Columns: Both dataset have 33 columns
Number of Rows: Maths dataset: 395, Portugese dataset: 649 
Kaggle Link: "https://www.kaggle.com/code/calcifer/alcohol-consumption-and-average-grades/notebook"

Survey Dataset:
We have collected data using Google survey for math grade and english grade from our school friend from school name Ryan "R" and  Johntallch "J".
Number of Columns: Both dataset have 33 columns
Number of Rows: Both dataset have 105 rows

# Exploratory Data Analysis
In this Exploratory Data Analysis, we will undertake preliminary investigations on original and collected datasets in order to uncover patterns, spot anomalies, test hypotheses, and evaluate assumptions using summary statistics and graphical representations.

```{r Load the packages, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(plyr)
library(dplyr)
library(gridExtra)
library(alluvial)
library(extrafont)
library(readr)
library(rpart)
library(waffle)
library(party)
library(randomForest)
library(styler)
library(knitr)
```

 
## Data Import
Original Dataset
We will import the data from a delimited csv file, we have original data set "student-mat.csv" which contains maths grades and "student-por.csv" which contains Portuguese grade, All column name are similar in both the data set.

New Dataset
We will import the data from a delimited csv file, we have gathered new data set "Student_Maths.csv"  which contains maths grades and "Student_English.csv"  which contains English grade, All column name are similar in both the data set.

```{r dataimport, echo=FALSE}

#Original data
d1 <- read.table("student-mat.csv",sep=",",header=TRUE) #Reading Math data set
d2 <- read.table("student-por.csv",sep=",",header=TRUE) #Reading Portuguese data set

#New survey data
data_english <- read.table("Student_English.csv",sep=",",header=TRUE) #Reading English data set
data_maths <- read.table("Student_Maths.csv",sep=",",header=TRUE) #Reading Maths data set

#Column rename
colnames(data_maths)[1] <- "school"   #Renaming "school" column name as it was incorrect format when uploaded from csv file.
colnames(data_english)[1] <- "school"
```

## Original Data Table View
In original Data Table, Please find complete details about the column name: Student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira), sex: "M" - Male, "F" - Female, age: student age ,Address:"U" - Urban,"R" Rural, famsize: - "GT3" - Greater than 3, "LT3" - Less than 3, Pstatus (Parent cohabitation Status): "T": Together, "A": Apart, Medu (Mother Education):(numeric: 0 - none, 1 - primary education (4th grade), 2 - 5th to 9th grade, 3 - secondary to higher secondary, 4 - University and above,  Fedu (Father's education): (numeric: 0 - none, 1 - primary education (4th grade), 2 - 5th to 9th grade, 3 - secondary to higher secondary, 4 - University and above, Mjob (Mother's job): at_home,teacher,services,health,other, Fjob (Father's Job): at_home,teacher,services,health,other, reason (reason to choose this school): close to home, school repuation, course preference,other, traveltime - Home to school travel time (numeric: 1 - upto 15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - above 1 hour), studytime - Weekly study time (numeric: 1 - less than 2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - more than 10 hours),  failures - Number of past class failures: 1,2,3,4, schoolsup - Extra educational support (binary: yes or no), famsup - Family educational support (binary: yes or no), activities - Extra-curricular activities (binary: yes or no),nursery - Attended nursery school (binary: yes or no), higher - Wants to take higher education (binary: yes or no),internet - Internet access at home (binary: yes or no), romantic - With a romantic relationship (binary: yes or no),  freetime - Free time after school (numeric: from 1 - very low to 5 - very high), goout - Going out with friends (numeric: from 1 - very low to 5 - very high), Dalc - Workday alcohol consumption (numeric: from 1 - very low to 5 - very high), Walc - Weekend alcohol consumption (numeric: from 1 - very low to 5 - very high),  health - Current health status (numeric: from 1 - very bad to 5 - very good),  G1 -  First period grade (numeric: from 0 to 20),  G2 - Second period grade (numeric: from 0 to 20), G3 - Final grade (numeric: from 0 to 20, output target).
```{r Data Merge for Original data, echo=FALSE}

#merging Original data sets by common columns into single Data set

data.source=merge(d1,d2,by=c("school","sex","age","address", "famsize", "Pstatus", "Medu", "Fedu", "Mjob", "Fjob", "reason", "nursery", "internet", "guardian","guardian","traveltime","studytime","failures", "schoolsup","famsup","activities","higher","romantic", "famrel", "freetime", "goout", "Dalc", "Walc", "health", "absences"))
```


```{r echo=FALSE, results= 'asis'}
kable(data.source[1:5,], caption = "Original Data set")
```
## New Survey Data Table View
In new dataset, school "R": 'Ryan', "J":Johntallch, rest variable name remain same as that of original dataset.

```{r Data Merge for New Data, echo=FALSE}

#merging New data sets by common columns into single Data set

new_data.source=merge(data_english,data_maths,by=c("school","sex","age","address","famsize","Pstatus", "Medu", "Fedu", "Mjob", "Fjob", "reason", "nursery", "internet", "guardian", "guardian", "traveltime", "studytime", "failures", "schoolsup", "famsup", "activities", "higher", "romantic", "famrel", "freetime", "goout", "Dalc", "Walc", "health", "absences"))

```

```{r echo=FALSE, results='asis'}
library(knitr)
kable(new_data.source[1:5,], caption = "New Data set")
```

## Comparision of alcohol consumption with sex 
We compared Workday alcohol consumption with age and sex from the original dataset to the new dataset and discovered that there are no high and very high consumption of alcohol in the original dataset on workday, as well as that women occupy a larger part in the very low consumption than male and almost no women found in the medium consumption of alcohol, whereas in the new dataset we discovered, which is quite strange because the consumption of alcohol is "high" and "very-high" for women as they occupy the larger area in the chart as compared to male.
```{r, echo=FALSE}
ggplot(data.source, aes(x = Dalc, y = age, color = sex)) +
geom_col()
```

```{r, echo=FALSE}
ggplot(new_data.source, aes(x = Dalc, y = age, color = sex)) +
geom_col()
```

We compared Weekend alcohol consumption with age and sex from the original dataset to the new dataset and discovered that there are significant differnces as compared to that with workday alcohol consumption. As clearly seen in orginal dataset there is also "very high" and "high" consumption of alcohol. In new data set women seems to outperform male in alcohol consumption in "high" category. 
```{r, echo=FALSE}
ggplot(data.source, aes(x = Walc, y = age, color = sex)) +
geom_col()
```
```{r, echo=FALSE}
ggplot(new_data.source, aes(x = Walc, y = age, color = sex)) +
geom_col()
```
# Data Visualization 
## Scatter Plot of grade comparision
Please see the scatter plot representations side by side on the left for the original dataset and on the right for the new survey data set. Below we have commented on our thoughts on the new survey data set and also offered the author's thoughts on the original data scatter plot.

Original Dataset:
The two scatter plots from original dataset have little meaning. First, none of the 85 students consumed excessive amounts of alcohol on a regular basis. Second, practically all of those who had pretty high scores consumed very little alcohol over the week. Third, math and Portuguese grades appear to be substantially correlated. The corrected R-squared is 0.55 when I regress Portuguese grades on math grades. This suggests that the correlation coefficient between math and Portuguese grades is around 0.74, and that change in math grades may explain approximately 55% of the variance in Portuguese grades. This, in my opinion, indicates that I may proceed with combining the two tables

New Survey Dataset:
The right scatter plot with new survey data shows us as follows. According to the Dalc scatterplot, the majority of the hue is extreme red "very low," indicating that students consume relatively little alcohol throughout the workday. According to Walc We might also conclude that the predominant color is green "medium" that occurred during. We can observe that the line in the new dataset plot is straight, indicating that there is a minor positive connection between enggrades and mathgrades, as opposed to the original dataset, which displays an extraordinarily strong positive correlation. As a result, we may combine these two tables as well.


```{r,  echo=FALSE}
# Original Data
# In this we have merged grade from period/semester 1 + period/semester 2 + period/semester 3 and calculated the mean of the grade using rowMean function, we did this separately for math grade and Portuguese grade.
data.source$mathgrades <- rowMeans(cbind(data.source$G1.x, data.source$G2.x, data.source$G3.x))
data.source$portgrades <- rowMeans(cbind(data.source$G1.y, data.source$G2.y, data.source$G3.y))

data.source$Dalc <- as.factor(data.source$Dalc) # converted from numeric to factor
data.source$Dalc <- mapvalues(data.source$Dalc, 
  from = 1:5,
  to = c("Very Low", "Low", "Medium", "High", "Very High") #Mapvalues to new variable name later will be used for ledger in plot.
)

#plot to compare math and portugese grade using geom smooth line.
str1 <- ggplot(data.source, aes(x = mathgrades, y = portgrades)) + 
  geom_point(aes(colour = factor(Dalc))) +
  scale_colour_hue(l = 25, c = 150) +
  geom_smooth(method = "lm", se = FALSE)

data.source$Walc <- as.factor(data.source$Walc) # converted from numeric to factor
data.source$Walc <- mapvalues(data.source$Walc, 
  from = 1:5,
  to = c("Very Low", "Low", "Medium", "High", "Very High") #Mapvalues to new variable name later will be used for ledger in plot.
)

# second plot to compare math and portugese grade using geom smooth line.
str2 <- ggplot(data.source, aes(x = mathgrades, y = portgrades)) +
  geom_point(aes(colour = factor(Walc))) +
  scale_colour_hue(l = 25, c = 150) +
  geom_smooth(method = "lm", se = FALSE)

#New Survey data 
# In this we have merged grade from period/semester 1 + period/semester 2 + period/semester 3 and calculated the mean of the grade using rowMean function, we did this separately for math grade and english grade
new_data.source$mathgrades <- rowMeans(cbind(new_data.source$G1.x, new_data.source$G2.x, new_data.source$G3.x))
new_data.source$enggrades <- rowMeans(cbind(new_data.source$G1.y, new_data.source$G2.y, new_data.source$G3.y))

new_data.source$Dalc <- as.factor(new_data.source$Dalc)
new_data.source$Dalc <- mapvalues(new_data.source$Dalc,
  from = 1:5,
  to = c("Very Low", "Low", "Medium", "High", "Very High")
)
#plot to compare math and english grade using geom smooth line 
new_str1 <- ggplot(new_data.source, aes(x = mathgrades, y = enggrades)) +
  geom_point(aes(colour = factor(Dalc))) +
  scale_colour_hue(l = 25, c = 150) +
  geom_smooth(method = "lm", se = FALSE)

new_data.source$Walc <- as.factor(new_data.source$Walc)
new_data.source$Walc <- mapvalues(new_data.source$Walc,
  from = 1:5,
  to = c("Very Low", "Low", "Medium", "High", "Very High")
)
# second plot to compare math and english grade using geom smooth line.
new_str2 <- ggplot(new_data.source, aes(x = mathgrades, y = enggrades)) +
  geom_point(aes(colour = factor(Walc))) +
  scale_colour_hue(l = 25, c = 150) +
  geom_smooth(method = "lm", se = FALSE)


grid.arrange(str1, new_str1, str2, new_str2, nrow = 2) #Side by side presentation of scatterplot
```


## Boxplot of average subject grades by daily alcohol consumption.
Please see the basic plot representations below for the original dataset and  for the new survey data set. Below we have commented on our thoughts on the new survey data set and also offered the author's thoughts on the original basic box plot.
Original Dataset:
The median average grade is noticeably higher among students who consume relatively little alcohol on a regular basis. The median grade of students with medium, high, and very high levels of daily alcohol intake, on the other hand, did not appear to be significantly different. As my first attempt at predicting average grades using all other factors, I will 1) do a multiple linear regression and 2) construct a regression tree of average grades on all other variables.Because variable "failures" is closely connected to my goal variable, avggrades, and both indicate the same general student aptitude (therefore it is more of a target than a feature), I am likely to delete variable "failures" from the dataset.

New Survey Dataset:
Unlike the original dataset, The median average grade differs significantly and is somewhat of an inverted normal distribution looking at it as students who consume relatively little alcohol and those who consume relatively high volumes of alcohol appear to have high Median average grades. Students who however have medium average consumption seem to have the lowest median average grades compared to the rest, thereby producing an inverted bell shaped distribution. It is however of key point to note that the distribution spread in average grades decreases with increased alcohol consumption as we see a decreased number of outliers as the intake scale increases, together with the shrink in the IQR ranges as well

```{r, echo=FALSE}
d3<-rbind(d1,d2) #combine the two datasets
# and eliminate the repeats:
d3norepeats<-d3 %>% distinct(school,sex,age,address,famsize,Pstatus,
                Medu,Fedu,Mjob,Fjob,reason,
                guardian,traveltime,studytime,failures,
                schoolsup, famsup,activities,nursery,higher,internet,
                romantic,famrel,freetime,goout,Dalc,Walc,health,absences, .keep_all = TRUE)
#add a column with average grades (math or Portuguese, whichever is available)
d3norepeats$avggrades=rowMeans(cbind(d3norepeats$G1,d3norepeats$G2,d3norepeats$G3))
# and drop grades in 3 marking periods.
d3norepeats<-d3norepeats[,-(31:33)]
```


```{r, echo=FALSE}
# New Survey Data
data_combine <- rbind(data_english, data_maths) # combine the two datasets
# and eliminate the repeats:
data_combine_norepeats <- data_combine %>% distinct(school, sex, age, address, famsize, Pstatus,
  Medu, Fedu, Mjob, Fjob, reason,
  guardian, traveltime, studytime, failures,
  schoolsup, famsup, activities, nursery, higher, internet,
  romantic, famrel, freetime, goout, Dalc, Walc, health, absences,
  .keep_all = TRUE
)
# add a column with average grades (math or Portuguese, whichever is available)
data_combine_norepeats$avggrades <- rowMeans(cbind(data_combine_norepeats$G1, data_combine_norepeats$G2, data_combine_norepeats$G3))
# and drop grades in 3 marking periods.
data_combine_norepeats <- data_combine_norepeats[, -(31:33)]
```


```{r, echo=FALSE}
ggplot(d3norepeats, aes(x = Dalc, y = avggrades, group = Dalc)) +
  geom_boxplot() +
  theme(legend.position = "none") +
  # scale_fill_manual(values=waffle.col)+
  xlab("Daily Alcohol consumption") +
  ylab("Average Grades") +
  ggtitle("Average Grade (Original Study)")
```


```{r, echo=FALSE}
# New Survey Data
ggplot(data_combine_norepeats, aes(x = Dalc, y = avggrades, group = Dalc)) +
  geom_boxplot() +
  theme(legend.position = "none") +
  # scale_fill_manual(values=waffle.col)+
  xlab("Daily Alcohol consumption") +
  ylab("Average Grades") +
  ggtitle("Average Grade (Reproducible Survey)")

```

# Adjusted R-squared
Below we have commented on our thoughts on the new survey data set and also offered the author's thoughts on the original data result of adjusted R-squared

Original Dataset:
In the preceding regression, the adjusted R-squared is just 0.17, which is fairly low. It means that variance in everything else explains just 17% of the variation in average grades. Studytime, schoolsup, paid, and higher are the variables that have a statistically significant influence on average grade.

<<<<<<< Updated upstream
New Survey Dataset:

=======
New Survey Dataset: In the below regression, the adjusted R-squared is 0.28, which is not very high but better than the original dataset. It means that variance in everything else explains just 28% of the variation in average grades. School, Mjob, absences are the variable that have a statistically significant influence over grade.
>>>>>>> Stashed changes

```{r, echo=FALSE}
failureind<-which(names(d3norepeats)=="failures")
d3norepeats<-d3norepeats[,-failureind]
```
```{r, echo=FALSE}
# 1) multiple regression
lm2<-lm(avggrades~., data=d3norepeats[,1:30])
summary(lm2)
```


```{r, echo=FALSE}
# predictions
rt2 <- rpart(avggrades ~ ., data = d3norepeats[, 1:30])
lm.predictions <- predict(lm2, d3norepeats)
rt.predictions <- predict(rt2, d3norepeats)
nmse.lm <- mean((lm.predictions - d3norepeats[, "avggrades"])^2) / mean((mean(d3norepeats$avggrades) - d3norepeats[, "avggrades"])^2)
nmse.rt <- mean((rt.predictions - d3norepeats[, "avggrades"])^2) / mean((mean(d3norepeats$avggrades) - d3norepeats[, "avggrades"])^2)
print(nmse.lm) # 0.80
print(nmse.rt) # 0.85
```
In the original, It seems that the linear model performs better than the regression tree as shown by the NMSE values. 

```{r, echo=FALSE}
#New Survey Data
failureind<-which(names(data_combine_norepeats)=="failures")
data_combine_norepeats<-data_combine_norepeats[,-failureind]
```
```{r, echo=FALSE}
# 1) multiple regression
lm2<-lm(avggrades~., data=data_combine_norepeats[,1:30])
summary(lm2)
```

```{r, echo=FALSE}
#New Survey Data
#predictions
rt2 <- rpart(avggrades ~ ., data = data_combine_norepeats[, 1:30])
lm.predictions <- predict(lm2, data_combine_norepeats)
rt.predictions <- predict(rt2, data_combine_norepeats)
nmse.lm <- mean((lm.predictions - data_combine_norepeats[, "avggrades"])^2) / mean((mean(data_combine_norepeats$avggrades) - data_combine_norepeats[, "avggrades"])^2)
nmse.rt <- mean((rt.predictions - data_combine_norepeats[, "avggrades"])^2) / mean((mean(data_combine_norepeats$avggrades) - data_combine_norepeats[, "avggrades"])^2)
print(nmse.lm) # 0.46
print(nmse.rt) # 0.59
```
Consistently, with the original dataset, we see that in our survey data, the linear model performs better than the regression tree as shown by the NMSE values. The results are however better in the survey dataset as compared to those of the original dataset which would suggest better quality in the data obtained
Plotted below will be error scatter plots

# Linear Model and Regression Tree
(Predicted grades vs True grades)
Below we have commented on our thoughts on the new survey data set and also offered the author's thoughts on the original data result of  Linear Model and the regression tree 
Original Dataset:
The horizontal axes in the graphs below show anticipated grades, while the vertical axes represent genuine grades. If the model accurately predicts real grades, projected grades must match actual grades, and hence the scatter points should align with the 45 degree (blue) line. Unfortunately, as seen by the NMSEs and error maps, neither of the two models appears to perform a good job of forecasting student average grades. I'm not happy with the results of linear regression and regression tree models, so I'm going to try a random forest.

New Survey Dataset:
As with the original plot, the definition of the axes is consistent and as per author recommendation, we are still expecting a close resemblance between actual grades and projected grades, meaning we expect the scatter point to cluster and align along or very close to the line. As compared to the initial plot, we note an improvement in the quality of our plot as the scatter points lie closer to the "line of best fit", however, we also recommend proceeding with the random forest model as we seek the model that gives us the best possible estimation.

```{r, echo=FALSE}
lmpltdata1 <- data.frame(cbind(lm.predictions, d3norepeats[, "avggrades"]))
colnames(lmpltdata1) <- c("lm.predictions", "avggrades")
rtpltdata1 <- data.frame(cbind(rt.predictions, d3norepeats[, "avggrades"]))
colnames(rtpltdata1) <- c("rt.predictions", "avggrades")

d3norepeats$Dalc <- as.factor(d3norepeats$Dalc)

errplt.lt1 <- ggplot(lmpltdata1, aes(lm.predictions, avggrades)) +
  geom_point(aes(color = d3norepeats[, "Dalc"])) +
  xlab("Predicted Grades (Linear Model)") +
  ylab("Actual Grades") +
  geom_abline(intercept = 0, slope = 1, color = "#0066CC", size = 1) +
  # geom_smooth(method = "lm", se = FALSE)+
  scale_colour_brewer(palette = "Set1", name = "Daily Alcohol \nConsumption")

errplt.rt1 <- ggplot(rtpltdata1, aes(rt.predictions, avggrades)) +
  geom_point(aes(color = d3norepeats[, "Dalc"])) +
  xlab("Predicted Grades (Regression Tree)") +
  ylab("Actual Grades") +
  geom_abline(intercept = 0, slope = 1, color = "#0066CC", size = 1) +
  # geom_smooth(method = "lm", se = FALSE)+
  scale_colour_brewer(palette = "Set1", name = "Daily Alcohol \nConsumption")

grid.arrange(errplt.lt1, errplt.rt1, nrow = 2)
```



```{r, echo=FALSE}
library(randomForest)
set.seed(4543)
rf2 <- randomForest(avggrades ~ ., data = d3norepeats[, 1:30], ntree = 500, importance = T)
rf.predictions <- predict(rf2, d3norepeats)
nmse.rf <- mean((rf.predictions - d3norepeats[, "avggrades"])^2) / mean((mean(d3norepeats$avggrades) - d3norepeats[, "avggrades"])^2)
print(nmse.rf) # 0.2
```


```{r, echo=FALSE}
#New Survey Data
lmpltdata1 <- data.frame(cbind(lm.predictions, data_combine_norepeats[, "avggrades"]))
colnames(lmpltdata1) <- c("lm.predictions", "avggrades")
rtpltdata1 <- data.frame(cbind(rt.predictions, data_combine_norepeats[, "avggrades"]))
colnames(rtpltdata1) <- c("rt.predictions", "avggrades")

data_combine_norepeats$Dalc <- as.factor(data_combine_norepeats$Dalc)

errplt.lt1 <- ggplot(lmpltdata1, aes(lm.predictions, avggrades)) +
  geom_point(aes(color = data_combine_norepeats[, "Dalc"])) +
  xlab("Predicted Grades (Linear Model)") +
  ylab("Actual Grades") +
  geom_abline(intercept = 0, slope = 1, color = "#0066CC", size = 1) +
  # geom_smooth(method = "lm", se = FALSE)+
  scale_colour_brewer(palette = "Set1", name = "Daily Alcohol \nConsumption")

errplt.rt1 <- ggplot(rtpltdata1, aes(rt.predictions, avggrades)) +
  geom_point(aes(color = data_combine_norepeats[, "Dalc"])) +
  xlab("Predicted Grades (Regression Tree)") +
  ylab("Actual Grades") +
  geom_abline(intercept = 0, slope = 1, color = "#0066CC", size = 1) +
  # geom_smooth(method = "lm", se = FALSE)+
  scale_colour_brewer(palette = "Set1", name = "Daily Alcohol \nConsumption")

grid.arrange(errplt.lt1, errplt.rt1, nrow = 2)
```
```{r, echo=FALSE}
library(randomForest)
set.seed(4543)
randfor <- randomForest(avggrades ~ ., data = data_combine_norepeats[, 1:30], ntree = 500, importance = T)
rf.predictions <- predict(randfor, data_combine_norepeats)
nmse.rf <- mean((rf.predictions - data_combine_norepeats[, "avggrades"])^2) / mean((mean(data_combine_norepeats$avggrades) - data_combine_norepeats[, "avggrades"])^2)
print(nmse.rf) # 0.17
```
# Random Forest

Below we have commented on our thoughts on the new survey data set and also offered the author's thoughts on the original data result of  Random Forest

Original Dataset:
The random forest implementation has an NMSE of 0.2, which is significantly lower than the NMSEs of the linear and regression tree models. As a validation, I will acquire the random forest error plot and compare it to the error plots produced before for the linear and regression tree models.

Despite the fact that random forest appears to regularly underpredict low grade earners and overpredict high grade earners, random forest appears to be a considerably better predictor of average grades than either the linear regression or regression tree model. 10 x 5 fold cross validation on my local machine confirms that the RF model with 500 trees is the best predictor of average student grades out of the three models that I executed With 500 points, I illustrate the relative relevance of all the characteristics in the dataset as determined by the Random Forest.

New Dataset:The random forest implementation has an NMSE of 0.17, which is significantly lower than the NMSEs of the linear and regression tree models. As a validation, I will acquire the random forest error plot and compare it to the error plots produced before for the linear and regression tree models.


```{r, echo=FALSE}
# first combine the rf predictions and actual scores in a single data frame
rfpltdata1 <- data.frame(cbind(rf.predictions, d3norepeats[, "avggrades"]))
colnames(rfpltdata1) <- c("rf.predictions", "avggrades")

# then create the error plot.
errplt.rf1<-ggplot(rfpltdata1,aes(rf.predictions,avggrades))+
  geom_point(aes(color=d3norepeats[,"Dalc"]))+
  xlab("Predicted Grades (Random Forest with 500 Trees)")+
  ylab("Actual Grades")+
  geom_abline(intercept=0,slope=1,color="#0066CC",size=1)+
  #geom_smooth(method = "lm", se = FALSE)+
  scale_colour_brewer(palette = "Set1",name = "Daily Alcohol \nConsumption")
#finally, plot the error plot from the random forest with the error plots of the linear and regression tree models.
grid.arrange(errplt.rf1, errplt.lt1,errplt.rt1,nrow=3)
```







```{r, echo=FALSE}
#New Survey Data
#first combine the rf predictions and actual scores in a single data frame
rfpltdata1=data.frame(cbind(rf.predictions,data_combine_norepeats[,"avggrades"]))
colnames(rfpltdata1)<-c("rf.predictions","avggrades")

# then create the error plot.
errplt.rf1 <- ggplot(rfpltdata1, aes(rf.predictions, avggrades)) +
  geom_point(aes(color = data_combine_norepeats[, "Dalc"])) +
  xlab("Predicted Grades (Random Forest with 500 Trees)") +
  ylab("Actual Grades") +
  geom_abline(intercept = 0, slope = 1, color = "#0066CC", size = 1) +
  # geom_smooth(method = "lm", se = FALSE)+
  scale_colour_brewer(palette = "Set1", name = "Daily Alcohol \nConsumption")
# finally, plot the error plot from the random forest with the error plots of the linear and regression tree models.
grid.arrange(errplt.rf1, errplt.lt1, errplt.rt1, nrow = 3)
```

# Conclusion

Original Dataset
The findings show that alcohol intake on both weekdays and weekends is an important predictor of student average grades. The removal of each of these two variables increases the MSE of predictions by 10-20%.

What's remarkable about these results is that certain traits that would be assumed to be essential did not make the top ten list (I would guess that variables like Pstatus, famsupport, famrel, and absences are among those), whilst others (like higher and Medu) turned out to be quite important.

Finally, the effect of the two most relevant factors, "higher" and "medu," on average student grade is as follows:

higher: a determination to seek higher education raises the average projected grade from 9.42 to 11.25. Thus, encouraging your children to seek higher education is the most effective way to enhance their academic performance!
Medu: Increasing the mother's education from none to more than secondary school raises the expected average grade from 10.8 to 11.5. Thus, future parents (particularly dads) should marry intelligent people if they want their children to do well in school.

New Dataset:
On the new dataset we see a completely different approach. Of keynot is the scale and the rearranged order of importance in the variable importance plot. Unlike the original study (where only 2 variables lay below 5%), in the new survey we have barely 7 variables lying on and around 5%+ inclusion in the MSE. The most important is the school with which the student attends and this does have an effect logically as the demographics, teacher staffing and availability of materials does infact impact the psychological perspective of a student

The number of absences with which the student has is also an important variable as removing this variable significantly increases the percentage MSE because again, logically it makes sense that a student with a higher numnber of absences will have their grades negatively affected hence the ranking of this variable higher up the hierarchy is justified.
The mother's job, daily alcohol consumption, sex, study time and frequency of going out with friends for any of the students seems to contribute significantly on the student's average grade. Again, removing these variables significantly increases the MSE.

```{r, echo=FALSE}
varImpPlot(rf2,type=1, main = "RF Variable Importance Plot (Original Data)") 
```
```{r, echo=FALSE}
varImpPlot(randfor,type=1, main = "RF Variable Importance Plot (Survey Data)") 
```

